# TalkScraper - Descripci√≥n del Proyecto

## Estado Actual del Proyecto ‚úÖ 
**Fase 1 COMPLETADA**: Recolecci√≥n de URLs de Conferencias
- ‚úÖ **206 conferencias √∫nicas recolectadas**
- ‚úÖ **122 conferencias en ingl√©s** (1971-presente, 53+ a√±os)
- ‚úÖ **84 conferencias en espa√±ol** (1990-presente, 34+ a√±os)
- ‚úÖ Base de datos SQLite implementada con deduplicaci√≥n autom√°tica
- ‚úÖ Soporte para p√°ginas de d√©cadas y URLs individuales hist√≥ricas

## Objetivo General
Desarrollar una aplicaci√≥n de Python que realice el scraping de las conferencias generales de la Iglesia de Jesucristo de los Santos de los √öltimos D√≠as en espa√±ol e ingl√©s.

## Fuente de Datos
- **URL principal**: https://www.churchofjesuschrist.org/study/general-conference?lang=eng
- **Par√°metro de idioma**: `lang` puede ser `eng` (ingl√©s) o `spa` (espa√±ol)

## Estructura de la P√°gina
### P√°gina Principal
La p√°gina principal funciona como un archivo de conferencias que contiene:
- Conferencias recientes (2020 en adelante)
- Enlaces a subarchivos organizados por d√©cadas para conferencias anteriores a 2020

### Frecuencia de Conferencias
- Las conferencias generales se realizan **dos veces por a√±o**:
  - **Abril** 
  - **Octubre**

## Funcionalidad del Scraper

### Fase 1: Recolecci√≥n de URLs ‚úÖ **COMPLETADA**
El scraper implementa exitosamente:
1. ‚úÖ Acceso a la p√°gina principal de conferencias
2. ‚úÖ Extracci√≥n de todas las URLs de conferencias de la p√°gina actual (~24 recientes)
3. ‚úÖ Identificaci√≥n y acceso a los subarchivos de d√©cadas anteriores:
   - 2010-2019 (20 conferencias)
   - 2000-2009 (20 conferencias) 
   - 1990-1999 (20 conferencias)
   - 1980-1989 (20 conferencias, solo ingl√©s)
4. ‚úÖ Recorrido sistem√°tico de todas las p√°ginas subsidiarias
5. ‚úÖ URLs individuales para a√±os hist√≥ricos (1971-1979, solo ingl√©s)
6. ‚úÖ **Lista primaria completa compilada**: 206 conferencias √∫nicas sin duplicados

**Resultado**: 
- **122 conferencias en ingl√©s** (1971-presente)
- **84 conferencias en espa√±ol** (1990-presente)

### Fase 2: Extracci√≥n de URLs de Discursos ‚è≥ **PR√ìXIMA**
Una vez obtenida la lista primaria de conferencias, el scraper deber√°:
1. Acceder a cada p√°gina de conferencia individual (206 p√°ginas)
2. Extraer las URLs de todos los discursos disponibles en cada conferencia
3. Filtrar √∫nicamente los discursos textuales (excluir entradas de solo video)
4. Compilar una **lista completa de discursos** organizada por conferencia
5. **Selector CSS identificado**: `li[data-content-type="general-conference-talk"] a`

### Fase 3: Descarga y Organizaci√≥n de Discursos üîÆ **FUTURO**
El scraper extraer√° cada discurso y lo organizar√° seg√∫n la siguiente estructura:

#### Estructura de Carpetas
```
/
‚îú‚îÄ‚îÄ eng/                    # Primer nivel: Idioma
‚îÇ   ‚îú‚îÄ‚îÄ 202504/            # Segundo nivel: Fecha (YYYYMM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ T√≠tulo del Discurso (Nombre del Orador).html
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ 202410/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ spa/                    # Primer nivel: Idioma
    ‚îú‚îÄ‚îÄ 202504/            # Segundo nivel: Fecha (YYYYMM)
    ‚îÇ   ‚îú‚îÄ‚îÄ T√≠tulo del Discurso (Nombre del Orador).html
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ 202410/
        ‚îî‚îÄ‚îÄ ...
```

#### Contenido de Archivos HTML
Cada archivo de discurso contendr√°:
1. **T√≠tulo del discurso** (etiqueta H1)
2. **Nombre del discursante**
3. **Posici√≥n/cargo del discursante**
4. **Contenido completo del discurso**
5. **Notas** (extracci√≥n obligatoria cuando existan)

#### Convenciones de Nomenclatura
- **Nombre de archivo**: Usar nombre com√∫n del discursante sin puntos (ejemplo: `Gordon B Hinckley`)
- **Contenido del archivo**: Usar nombre completo con t√≠tulo formal (ejemplo: `Presidente Gordon B. Hinckley`)

#### Criterios de Filtrado
- **Incluir**: Discursos textuales completos
- **Excluir**: Entradas que sean √∫nicamente videos sin contenido textual

## Caracter√≠sticas T√©cnicas Avanzadas

### Procesamiento por Lotes
Dado el alto volumen de discursos (aproximadamente **50 discursos por conferencia**), el sistema implementar√°:
- **Ejecuci√≥n incremental**: Capacidad de reanudar el procesamiento desde donde se interrumpi√≥ la ejecuci√≥n anterior
- **Procesamiento por lotes**: Divisi√≥n del trabajo en lotes manejables para optimizar el rendimiento
- **Persistencia de estado**: Almacenamiento del progreso para permitir continuidad entre ejecuciones

### Control de Errores
- **Manejo robusto de excepciones**: Captura y gesti√≥n de errores de red, parsing y E/O
- **Reintentos autom√°ticos**: Estrategia de reintento para conexiones fallidas
- **Logging detallado**: Registro comprehensivo de errores y progreso
- **Recuperaci√≥n graceful**: Capacidad de continuar el procesamiento despu√©s de errores no cr√≠ticos

### Principios de Desarrollo
El c√≥digo seguir√° los **principios SOLID** y mejores pr√°cticas:
- **Single Responsibility**: Cada clase/m√≥dulo con una responsabilidad espec√≠fica
- **Open/Closed**: Extensible sin modificar c√≥digo existente
- **Liskov Substitution**: Interfaces consistentes y substituibles
- **Interface Segregation**: Interfaces espec√≠ficas y cohesivas
- **Dependency Inversion**: Dependencias hacia abstracciones, no implementaciones

### Patrones de Dise√±o Aplicables
- **Strategy Pattern**: Para diferentes estrategias de scraping seg√∫n el tipo de p√°gina
- **Factory Pattern**: Para creaci√≥n de scrapers espec√≠ficos por idioma/per√≠odo
- **Observer Pattern**: Para notificaci√≥n de progreso y eventos
- **Command Pattern**: Para operaciones de scraping reutilizables y reversibles

### Requisitos T√©cnicos
- **Lenguaje**: Python
- **Soporte multiidioma**: Espa√±ol e Ingl√©s
- **Cobertura temporal**: Desde las conferencias m√°s antiguas disponibles hasta las m√°s recientes

## Especificaciones T√©cnicas Detalladas

### Tecnolog√≠as y Librer√≠as
- **P√°ginas est√°ticas**: No requiere JavaScript para contenido principal
- **Notas**: Requieren procesamiento JavaScript - extracci√≥n obligatoria
- **Autenticaci√≥n**: No se requiere login
- **Codificaci√≥n**: UTF-8 para soporte completo de acentos y diacr√≠ticos

#### Librer√≠as Recomendadas
- **Web Scraping**:
  - `requests`: Para realizar peticiones HTTP de manera eficiente
  - `beautifulsoup4`: Para parsing de HTML est√°tico
  - `selenium`: Requerido para extracci√≥n de notas con JavaScript
- **Concurrencia**:
  - `asyncio` + `aiohttp`: Para procesamiento as√≠ncrono de m√∫ltiples discursos
  - `concurrent.futures`: Para manejo de hilos en operaciones I/O
- **Persistencia y Estado**:
  - `sqlite3` (built-in): Para almacenar estado y progreso del scraping
  - `json` (built-in): Para archivo de configuraci√≥n
- **Logging y Monitoreo**:
  - `logging` (built-in): Para sistema de logs b√°sico
  - `tqdm`: Para barras de progreso en CLI
- **Manejo de Archivos**:
  - `pathlib` (built-in): Para manejo robusto de rutas de archivos
  - `unicodedata` (built-in): Para normalizaci√≥n de caracteres especiales
- **CLI y Configuraci√≥n**:
  - `argparse` (built-in): Para interfaz de l√≠nea de comandos
  - `configparser` (built-in): Para manejo del archivo de configuraci√≥n
- **Utilidades**:
  - `urllib.parse` (built-in): Para manipulaci√≥n de URLs
  - `time` (built-in): Para delays entre requests
  - `re` (built-in): Para expresiones regulares en limpieza de texto

### Configuraci√≥n de Rendimiento
- **Velocidad de requests**: Sin l√≠mite espec√≠fico, pero aplicar principios razonables
- **Procesamiento concurrente**: 3-5 discursos simult√°neos
- **Almacenamiento**: Sin restricciones actuales

### Configuraci√≥n del Sistema
- **Archivo de configuraci√≥n**: Requerido para par√°metros del sistema
- **Interfaz de l√≠nea de comandos**: Necesaria para integraci√≥n con Task Scheduler de Windows
- **Logging**: B√°sico y enfocado - inicio/fin de operaciones y errores √∫nicamente

### Manejo de Casos Especiales
- **T√≠tulos duplicados**: Los discursos pueden tener t√≠tulos id√©nticos en diferentes conferencias
- **Extensi√≥n de discursos**: Incluir contenido completo sin l√≠mite de longitud
- **Caracteres especiales**: Manejo robusto de acentos y diacr√≠ticos en nombres de archivos