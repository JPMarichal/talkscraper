#!/usr/bin/env python3
"""
Script para limpiar URLs inv√°lidas de la base de datos
"""

import sqlite3
import re
from urllib.parse import urlparse

def is_valid_conference_url(url: str) -> bool:
    """
    Valida si una URL es una conferencia real.
    
    URLs v√°lidas:
    - https://www.churchofjesuschrist.org/study/general-conference/2025/04?lang=eng
    - https://www.churchofjesuschrist.org/study/general-conference/1975/10?lang=spa
    
    URLs inv√°lidas:
    - URLs de d√©cadas: /2010-2019, /1990-1999, etc.
    - URLs de oradores: /speakers/
    - URLs de manuales: /manual/
    - Dominio incorrecto: conference.lds.org
    """
    try:
        parsed = urlparse(url)
        
        # Verificar dominio correcto (ambos dominios son v√°lidos)
        valid_domains = [
            'www.churchofjesuschrist.org',
            'churchofjesuschrist.org', 
            'conference.churchofjesuschrist.org',
            'conference.lds.org'  # Dominio anterior, a√∫n v√°lido por redirecci√≥n
        ]
        if parsed.netloc not in valid_domains:
            return False
        
        # Verificar que sea una URL de conferencia general
        if '/study/general-conference/' not in parsed.path:
            return False
        
        # Verificar que NO sea una URL de p√°ginas especiales
        if any(x in parsed.path for x in ['/speakers/', '/manual/', '/topics/']):
            return False
        
        # Extraer la parte despu√©s de /study/general-conference/
        path_parts = parsed.path.strip('/').split('/')
        
        if len(path_parts) < 4:  # Debe tener al menos: study, general-conference, a√±o, mes
            return False
        
        if path_parts[0] != 'study' or path_parts[1] != 'general-conference':
            return False
        
        year_month = path_parts[2:4]  # [a√±o, mes]
        
        # Verificar formato de a√±o (4 d√≠gitos)
        if not re.match(r'^\d{4}$', year_month[0]):
            return False
        
        # Verificar formato de mes (04 o 10)
        if year_month[1] not in ['04', '10']:
            return False
        
        # Verificar que el a√±o est√© en un rango razonable (1971-2030)
        year = int(year_month[0])
        if year < 1971 or year > 2030:
            return False
        
        return True
        
    except Exception:
        return False

def clean_database():
    """Limpia URLs inv√°lidas de la base de datos."""
    db_path = 'talkscraper_state.db'
    
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        # Obtener todas las URLs
        cursor.execute('SELECT id, url, language FROM conference_urls')
        all_urls = cursor.fetchall()
        
        print(f'Analizando {len(all_urls)} URLs en la base de datos...')
        
        valid_urls = []
        invalid_urls = []
        
        for url_id, url, language in all_urls:
            if is_valid_conference_url(url):
                valid_urls.append((url_id, url, language))
            else:
                invalid_urls.append((url_id, url, language))
        
        print(f'\nüìä Resultados del an√°lisis:')
        print(f'   ‚úÖ URLs v√°lidas: {len(valid_urls)}')
        print(f'   ‚ùå URLs inv√°lidas: {len(invalid_urls)}')
        
        if invalid_urls:
            print(f'\n‚ùå URLs inv√°lidas encontradas:')
            for url_id, url, language in invalid_urls[:10]:  # Mostrar primeras 10
                print(f'   {language.upper()}: {url}')
            if len(invalid_urls) > 10:
                print(f'   ... y {len(invalid_urls) - 10} m√°s')
            
            # Preguntar confirmaci√≥n antes de borrar
            response = input(f'\n¬øDesea eliminar {len(invalid_urls)} URLs inv√°lidas? (s/N): ')
            
            if response.lower() in ['s', 'y', 'yes', 's√≠']:
                # Eliminar URLs inv√°lidas
                invalid_ids = [url_id for url_id, _, _ in invalid_urls]
                cursor.executemany('DELETE FROM conference_urls WHERE id = ?', 
                                 [(url_id,) for url_id in invalid_ids])
                
                # Tambi√©n eliminar talk_urls asociadas
                cursor.executemany('DELETE FROM talk_urls WHERE conference_url = ?',
                                 [(url,) for _, url, _ in invalid_urls])
                
                conn.commit()
                
                print(f'‚úÖ {len(invalid_urls)} URLs inv√°lidas eliminadas de la base de datos')
                
                # Verificar estad√≠sticas finales
                cursor.execute('SELECT language, COUNT(*) FROM conference_urls GROUP BY language')
                final_stats = cursor.fetchall()
                
                print(f'\nüìä Estad√≠sticas finales:')
                for lang, count in final_stats:
                    print(f'   {lang.upper()}: {count} conferencias v√°lidas')
            else:
                print('‚ùå Operaci√≥n cancelada. No se eliminaron URLs.')
        else:
            print('‚úÖ No se encontraron URLs inv√°lidas.')

if __name__ == '__main__':
    clean_database()
